{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.nbeats import *\n",
    "from models.loaders import *\n",
    "from models.losses import *\n",
    "import tensorboard as tb\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set M4 data parameters\n",
    "\n",
    "# Hourly, Daily, Weekly, Monthly, Quarterly, Yearly\n",
    "seasonal_period= \"Daily\"\n",
    "\n",
    "# Any index will do since we are just loading a representative entry from the M4Info.csv file to gather data parameters\n",
    "data_index = 1 \n",
    "\n",
    "# The backcast lenght is determined by multiplying the forecast horizon by an integer multiplier\n",
    "forecast_multiplier = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer(max_epochs=100, fast_dev_run=False, val_nepoch=1, chk_cb = None, logger = None):\n",
    "  trainer =  pl.Trainer(\n",
    "    accelerator='auto'\n",
    "    ,max_epochs=max_epochs   \n",
    "    ,fast_dev_run=fast_dev_run\n",
    "    ,logger=[logger]\n",
    "    ,check_val_every_n_epoch=val_nepoch \n",
    "    ,callbacks=[chk_cb]\n",
    "  )\n",
    "  return trainer\n",
    "\n",
    "\n",
    "def get_M4infofile_info(info_file,seasonal_period, forecast_multiplier, data_index = 1):\n",
    "  \n",
    "  data_info  = pd.read_csv(info_file, index_col=0)\n",
    "  data_id_info = data_info.loc[seasonal_period[0] + f\"{data_index}\"]\n",
    "  category = data_id_info.category\n",
    "  frequency = data_id_info.Frequency\n",
    "  forecast = data_id_info.Horizon\n",
    "  backcast = data_id_info.Horizon * forecast_multiplier\n",
    "  \n",
    "  return category, frequency, forecast, backcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "info_file  = \"data/M4/M4-info.csv\"\n",
    "train_file = f\"data/M4/Train/{seasonal_period}-train.csv\"\n",
    "test_file  = f\"data/M4/Test/{seasonal_period}-test.csv\"\n",
    "\n",
    "# Get data parameters from M4Info.csv file\n",
    "category, frequency, forecast, backcast = get_M4infofile_info(\n",
    "  info_file, seasonal_period, forecast_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model hyperparameters\n",
    "optimizer = 'adam'\n",
    "loss = 'smape' \n",
    "hidden_layer_units = 512\n",
    "share_weights_in_stack = False\n",
    "learning_rate = 1e-5\n",
    "thetas_dim = 5\n",
    "stack_blocks = 1\n",
    "\n",
    "# Set trainer hyperparameters\n",
    "batch_size = 1024 # N-BEATS paper uses 1024\n",
    "val_nepoch = 1 # perform a validation check every n epochs\n",
    "max_epochs = 100\n",
    "train = True\n",
    "test = True\n",
    "split_ratio = 0.8\n",
    "debug = True\n",
    "fast_dev_run = False\n",
    "chkpoint = None # set to checkpoint path if you want to load a previous model\n",
    "loss = SMAPELoss()\n",
    "\n",
    "\n",
    "# set precision to 32 bit\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Define model architecture\n",
    "# trend blocks should generally be paired with seasonality blocks, but 1:1 pairing \n",
    "# doesn't seem to be necessary. The N-BEATS paper shows that ensembles of different\n",
    "# varations in stack architecture offer the best performance gains.\n",
    "stack_types =[NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,              \n",
    "              NBeatsNet.GENERIC_BLOCK              \n",
    "              ]\n",
    "\n",
    "if chkpoint is not None:  \n",
    "  model = NBeatsNet.load_from_checkpoint(chkpoint)\n",
    "else:\n",
    "  model = NBeatsNet(\n",
    "    stack_types = stack_types,\n",
    "    n_forecast = forecast, \n",
    "    n_backcast = backcast,\n",
    "    loss = loss,  \n",
    "    learning_rate = learning_rate,\n",
    "    thetas_dim = thetas_dim,\n",
    "    blocks_per_stack = stack_blocks,\n",
    "    share_weights_in_stack = share_weights_in_stack,\n",
    "    hidden_layer_units = hidden_layer_units,\n",
    "    optimizer = optimizer,\n",
    "    no_val = False,\n",
    "    freq = frequency\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a tensorboard loger\n",
    "name = f\"n-beats-{loss}-s{seasonal_period}-B+H:{backcast}+{forecast}-f:{frequency}\" \n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"logs/\", name=name)\n",
    "  \n",
    "chk_callback = ModelCheckpoint(\n",
    "  save_top_k=3,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\",\n",
    "  filename=\"{name}-{epoch:02d}-{val_loss:.2f}\",\n",
    ")\n",
    "  \n",
    "trainer = get_trainer(\n",
    "                      max_epochs=max_epochs, \n",
    "                      fast_dev_run=fast_dev_run, \n",
    "                      val_nepoch=val_nepoch, \n",
    "                      chk_cb=chk_callback, \n",
    "                      logger=tb_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "if train: \n",
    "  \n",
    "  dmc = TimeSeriesCollectionDataModule(\n",
    "    train_file=train_file, \n",
    "    backcast=backcast, \n",
    "    forecast=forecast, \n",
    "    batch_size=batch_size, \n",
    "    split_ratio=split_ratio\n",
    "    )\n",
    "  trainer.fit(model, datamodule=dmc, ckpt_path=chkpoint)\n",
    "  trainer.validate(model, datamodule=dmc)\n",
    "  \n",
    "if test:\n",
    "  \n",
    "  test_module = TimeSeriesCollectionTestModule(\n",
    "    test_file=test_file, \n",
    "    train_file=train_file,\n",
    "    backcast=backcast, \n",
    "    forecast=forecast, \n",
    "    batch_size=batch_size\n",
    "  )\n",
    "  trainer.test(model, datamodule=test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbeats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

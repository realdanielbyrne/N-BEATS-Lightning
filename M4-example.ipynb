{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.nbeats import *\n",
    "from models.loaders import *\n",
    "from models.losses import *\n",
    "import tensorboard as tb\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set M4 data parameters\n",
    "\n",
    "# Hourly, Daily, Weekly, Monthly, Quarterly, Yearly\n",
    "seasonal_period= \"Monthly\"\n",
    "\n",
    "# Any index will do since we are just loading a representative entry from the M4Info.csv file to gather data parameters\n",
    "data_index = 1 \n",
    "\n",
    "# The backcast lenght is determined by multiplying the forecast horizon by an integer multiplier\n",
    "forecast_multiplier = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer(max_epochs=100, fast_dev_run=False, val_nepoch=1, chk_cb = None, logger = None):\n",
    "  trainer =  pl.Trainer(\n",
    "    accelerator='auto'\n",
    "    ,max_epochs=max_epochs   \n",
    "    ,fast_dev_run=fast_dev_run\n",
    "    ,logger=[logger]\n",
    "    ,check_val_every_n_epoch=val_nepoch \n",
    "    ,callbacks=[chk_cb]\n",
    "  )\n",
    "  return trainer\n",
    "\n",
    "\n",
    "def get_M4infofile_info(info_file,seasonal_period, forecast_multiplier, data_index = 1):\n",
    "  \n",
    "  data_info  = pd.read_csv(info_file, index_col=0)\n",
    "  data_id_info = data_info.loc[seasonal_period[0] + f\"{data_index}\"]\n",
    "  category = data_id_info.category\n",
    "  frequency = data_id_info.Frequency\n",
    "  forecast = data_id_info.Horizon\n",
    "  backcast = data_id_info.Horizon * forecast_multiplier\n",
    "  \n",
    "  return category, frequency, forecast, backcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "info_file  = \"data/M4/M4-info.csv\"\n",
    "train_file = f\"data/M4/Train/{seasonal_period}-train.csv\"\n",
    "test_file  = f\"data/M4/Test/{seasonal_period}-test.csv\"\n",
    "\n",
    "# Get data parameters from M4Info.csv file\n",
    "category, frequency, forecast, backcast = get_M4infofile_info(\n",
    "  info_file, seasonal_period, forecast_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model hyperparameters\n",
    "optimizer = 'adam'\n",
    "loss = 'smape' \n",
    "hidden_layer_units = 512\n",
    "share_weights_in_stack = False\n",
    "learning_rate = 1e-5\n",
    "thetas_dim = 5\n",
    "stack_blocks = 1\n",
    "\n",
    "# Set trainer hyperparameters\n",
    "batch_size = 1024 # N-BEATS paper uses 1024\n",
    "val_nepoch = 1 # perform a validation check every n epochs\n",
    "max_epochs = 2\n",
    "train = True # set to True to train the model\n",
    "test = True # set to True to test the model\n",
    "split_ratio = 0.8\n",
    "fast_dev_run = False  # set to True to run a single batch through the model for debugging purposes\n",
    "debug = True # set to True t limit the size of the dataset for debugging purposes\n",
    "chkpoint = None # set to checkpoint path if you want to load a previous model\n",
    "loss = SMAPELoss() # Any Pytorch loss function will do.  N-BEATS paper uses MAPELoss, SMAPELoss, and MASELoss\n",
    "\n",
    "\n",
    "\n",
    "# set precision to 32 bit\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Define model architecture\n",
    "# trend blocks should generally be paired with seasonality blocks, but 1:1 pairing \n",
    "# doesn't seem to be necessary. The N-BEATS paper shows that ensembles of different\n",
    "# varations in stack architecture offer the best performance gains.\n",
    "stack_types =[NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,\n",
    "              NBeatsNet.GENERIC_BLOCK,              \n",
    "              NBeatsNet.GENERIC_BLOCK              \n",
    "              ]\n",
    "\n",
    "if chkpoint is not None:  \n",
    "  model = NBeatsNet.load_from_checkpoint(chkpoint)\n",
    "else:\n",
    "  model = NBeatsNet(\n",
    "    loss_fn = loss,  \n",
    "    optimizer = optimizer,\n",
    "    stack_types = stack_types,\n",
    "    n_forecast = forecast, \n",
    "    n_backcast = backcast,\n",
    "    learning_rate = learning_rate,\n",
    "    thetas_dim = thetas_dim,\n",
    "    blocks_per_stack = stack_blocks,\n",
    "    share_weights_in_stack = share_weights_in_stack,\n",
    "    hidden_layer_units = hidden_layer_units,\n",
    "    no_val = False\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a tensorboard loger\n",
    "name = f\"n-beats-{loss}-{seasonal_period}-{backcast}-{forecast}-{frequency}\" \n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"logs/\", name=name)\n",
    "  \n",
    "chk_callback = ModelCheckpoint(\n",
    "  save_top_k=3,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\",\n",
    "  filename=\"{name}-{epoch:02d}-{val_loss:.2f}\",\n",
    ")\n",
    "  \n",
    "trainer = get_trainer(\n",
    "                      max_epochs=max_epochs, \n",
    "                      fast_dev_run=fast_dev_run, \n",
    "                      val_nepoch=val_nepoch, \n",
    "                      chk_cb=chk_callback, \n",
    "                      logger=tb_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "if train: \n",
    "  \n",
    "  dmc = TimeSeriesCollectionDataModule(\n",
    "    train_file=train_file, \n",
    "    backcast=backcast, \n",
    "    forecast=forecast, \n",
    "    batch_size=batch_size, \n",
    "    split_ratio=split_ratio,\n",
    "    debug=debug\n",
    "    )\n",
    "  trainer.fit(model, datamodule=dmc, ckpt_path=chkpoint)\n",
    "  trainer.validate(model, datamodule=dmc)\n",
    "  \n",
    "if test:\n",
    "  \n",
    "  test_module = TimeSeriesCollectionTestModule(\n",
    "    test_file=test_file, \n",
    "    train_file=train_file,\n",
    "    backcast=backcast, \n",
    "    forecast=forecast, \n",
    "    batch_size=batch_size\n",
    "  )\n",
    "  trainer.test(model, datamodule=test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbeats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-BEATS-Lightning \n",
    "\n",
    "**N-BEATS** represents a cutting-edge model, demonstrating the effectiveness of **pure DL architectures** when it comes to time-series forecasting. It surpasses the performance of traditional statistical methods in the *M3* and *M4* competitions. For a more in-depth understanding of the model, refer to: https://arxiv.org/pdf/1905.10437.pdf.\n",
    "\n",
    "The **milk production** dataset describes a time-series of milk production (in pounds per cow) over 13 years (1962-1974), and there are 156 observations. We use the first 80% of the observations for training and testing various models while holding back the remaining observations for validating the final model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics and Visualizations \n",
    "\n",
    "We begin by reading the data and summarizing the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>milk_production_pounds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1962-01</th>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-02</th>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-03</th>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-04</th>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-05</th>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         milk_production_pounds\n",
       "month                          \n",
       "1962-01                     589\n",
       "1962-02                     561\n",
       "1962-03                     640\n",
       "1962-04                     656\n",
       "1962-05                     727"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Import necessary libraries\n",
    "from lightningnbeats import NBeatsNet\n",
    "from lightningnbeats.loaders import *\n",
    "import pandas as pd\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "tqdm.pandas()\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorboard\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the milk.csv dataset\n",
    "milk = pd.read_csv('../src/lightningnbeats/data/milk.csv', index_col=0)\n",
    "milkval = milk.values.flatten() # flat numpy array\n",
    "milk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of two columns:\n",
    "\n",
    "- *month:*  The month during which the data was collected, starting from January 1962.\n",
    "- *milk_production_pounds:*   The amount of milk produced in pounds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milk.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'month' column to datetime format\n",
    "milk['month'] = pd.to_datetime(milk.index)\n",
    "\n",
    "# Create Time Series Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(milk['month'], milk['milk_production_pounds'], label='Milk Production')\n",
    "plt.title('Time Series Plot of Milk Production')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Milk Production (pounds)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Time Series Plot above illustrates the trend and seasonality in milk production over time.\n",
    "It's apparent that there's a recurring pattern every year, which suggests a strong seasonal\n",
    "component. Additionally, there seems to be a general upward trend in milk production over the years.\n",
    "Next, let's move on to the Seasonal Decomposition to decompose the time series into its trend,\n",
    "seasonal, and residual components. This will provide a clearer picture of the underlying patterns\n",
    "in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milk.set_index('month', inplace=True)\n",
    "\n",
    "# Perform seasonal decomposition\n",
    "decomposition = seasonal_decompose(milk['milk_production_pounds'], model='multiplicative')\n",
    "\n",
    "# Plot the seasonal decomposition again with the corrected attribute name\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(411)\n",
    "plt.plot(decomposition.trend, label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(decomposition.seasonal, label='Seasonal')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(decomposition.resid, label='Residual')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(milk['milk_production_pounds'], label='Observed')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Seasonal Decomposition plot breaks down the time series into three components:\n",
    "\n",
    "* Trend: Shows a general upward trend in milk production over the years.\n",
    "* Seasonal: Illustrates a clear seasonal pattern that repeats every year.\n",
    "* Residual: Contains the residual values after the trend and seasonal components have\n",
    "been removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Specification\n",
    "\n",
    "Next we will create a PyTorch Lightning DataModule to load the data, and 3 nbeats_lightning models, 2 generic, and 1 interpretable, with which to train the data and then predict.  We will then compare the predictions of the two models\n",
    "against the actual data and to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Define the Generic N-Beats Models\n",
    "# Generic hyperparameters\n",
    "forecast_length = 6\n",
    "backcast_length = 4 * forecast_length\n",
    "batch_size = 64\n",
    "n_stacks = 6\n",
    "\n",
    "g_blocks_per_stack = 1\n",
    "g_width = 512\n",
    "active_g = False\n",
    "\n",
    "\n",
    "# Create a simple pytorch dataloader\n",
    "dm = TimeSeriesDataModule(\n",
    "  data=milkval,\n",
    "  batch_size=batch_size,\n",
    "  backcast_length=backcast_length,\n",
    "  forecast_length=forecast_length)\n",
    "\n",
    "\n",
    "stacks = [ 'Generic']\n",
    "n_stacks = n_stacks//len(stacks)  \n",
    "stack_types = stacks * n_stacks\n",
    "no_val=False\n",
    "\n",
    "g1 = NBeatsNet (\n",
    "  backcast_length = backcast_length,\n",
    "  forecast_length = forecast_length, \n",
    "  stack_types = stack_types,\n",
    "  n_blocks_per_stack = 1,\n",
    "  share_weights = True, \n",
    "  thetas_dim = 5,      \n",
    "  loss = 'SMAPELoss',\n",
    "  active_g = False,\n",
    "  latent_dim = 4,\n",
    "  no_val=no_val,\n",
    ") \n",
    "\n",
    "model_id=\"\".join(stacks)\n",
    "g1_name = f\"{model_id}[{backcast_length},{forecast_length}]-{n_stacks=}-{active_g=}\" \n",
    "print(\"Model Name :\", g1_name)\n",
    "\n",
    "# Same model as above, but with g-activation = True.\n",
    "# g-activation applies an activation funtion to the linear (gb and gf) layers\n",
    "# which are in the last layer of each block and have as parametes the \n",
    "# theta coefficients found in the preceding layer. Application of this activation\n",
    "# helps the generic model converge faster.\n",
    "\n",
    "g2 = NBeatsNet (\n",
    "  backcast_length = backcast_length,\n",
    "  forecast_length = forecast_length, \n",
    "  stack_types = stack_types,\n",
    "  n_blocks_per_stack = 1,\n",
    "  share_weights = True, \n",
    "  thetas_dim = 5,      \n",
    "  loss = 'SMAPELoss',\n",
    "  active_g = True,\n",
    "  no_val=no_val,\n",
    ") \n",
    "g2_name = f\"{model_id}[{backcast_length},{forecast_length}]-{n_stacks=}-{active_g=}\" \n",
    "print(\"Model Name :\", g2_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the model `g2` is identical to `g1` except that it has enabled the `active_g` parameter. This parameter when enabled applies the model's activation funtion to the linear funtions (gb and gf) which are found by the network in the last layer of each block using the theta parameters found in the preceding layer. \n",
    "\n",
    "You can enable this feature by setting `active_g` to `True`.  Enabling this activation function seems to help the Generic model converge. The parameter `active_g` is not a feature found in the original N-Beats paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Interpretable N-Beats Model\n",
    "\n",
    "stacks = ['Trend', 'Seasonality']\n",
    "# Interpretable Hyperparameters\n",
    "n_blocks_per_stack = 3\n",
    "t_width = 256\n",
    "s_width = 2048\n",
    "\n",
    "\n",
    "# An Interpretable N-Beats Model, \n",
    "#  - 2 stacks \n",
    "#     - 3 trend(256) blocks in first stack (default size)\n",
    "#     - 3 seasonality(2048) in second stack (default size)\n",
    "interpretable_milkmodel = NBeatsNet(\n",
    "  stack_types=stacks,\n",
    "  backcast_length = backcast_length,\n",
    "  forecast_length = forecast_length, \n",
    "  n_blocks_per_stack = n_blocks_per_stack,\n",
    "  thetas_dim = 5,    \n",
    "  t_width=t_width,  \n",
    "  s_width=s_width,\n",
    "  share_weights = True\n",
    ")\n",
    "\n",
    "i_name = f\"Interpretable-[{backcast_length}-{forecast_length}]-s[2-{n_blocks_per_stack}]-[{t_width}-{s_width}]\" \n",
    "print(\"Model Name :\", i_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we train the base Generic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model checkpoint callback\n",
    "g1_chk_callback = ModelCheckpoint(\n",
    "  save_top_k = 1, # save top model\n",
    "  monitor = \"val_loss\", # monitor validation loss as evaluation \n",
    "  mode = \"min\",\n",
    "  filename = \"{name}-{epoch:02d}-{val_loss:.2f}\",\n",
    ")\n",
    "\n",
    "# Define a tensorboard loger\n",
    "\n",
    "g1_tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"lightning_logs/\", name=g1_name)\n",
    "\n",
    "\n",
    "# Train the generic model\n",
    "generic_trainer =  pl.Trainer(\n",
    "  accelerator='auto' # use GPU if available\n",
    "  ,max_epochs=500\n",
    "  ,callbacks=[g1_chk_callback]  \n",
    "  ,logger=[g1_tb_logger]\n",
    ")\n",
    "\n",
    "generic_trainer.fit(g1, datamodule=dm)\n",
    "generic_trainer.validate(g1, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we train the generic model with `active_g=True`.  Generally this results in a comparably accurate model in fewer training cycles, when the Generic model converges.  Generic models without an activation on the g layers might not converge at all in fact.   This parameter fixes this shortcoming of the original model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the generic model with active_g\n",
    "\n",
    "# Define a model checkpoint callback\n",
    "gact_chk_callback = ModelCheckpoint(\n",
    "  save_top_k = 2, # save top 2 models\n",
    "  monitor = \"val_loss\", # monitor validation loss as evaluation \n",
    "  mode = \"min\",\n",
    "  filename = \"{name}-{epoch:02d}-{val_loss:.2f}\",\n",
    ")\n",
    "# Define a tensorboard loger\n",
    "gact_tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"lightning_logs/\", name=g2_name)\n",
    "\n",
    "generic_act_trainer =  pl.Trainer(\n",
    "  accelerator='auto' # use GPU if available\n",
    "  ,max_epochs=500\n",
    "  ,callbacks=[gact_chk_callback]  \n",
    "  ,logger=[gact_tb_logger]\n",
    ")\n",
    "\n",
    "generic_act_trainer.fit(g2, datamodule=dm)\n",
    "generic_act_trainer.validate(g2, datamodule=dm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we train the interpretable model.  This model defaults to using only two stacks, per the original paper.  The first stack is the Trend stack, and the second stack is the Seasonal stack.  The Trend stack removes the trend component of the signal, and the Seasonal stack removes the seasonal component of the signal.  The residual component is then used to make the final prediction mirroring the technique used in the traditional statistical method Holt-Winters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Define a model checkpoint callback\n",
    "i_chk_callback = ModelCheckpoint(\n",
    "  save_top_k = 2, # save top 2 models\n",
    "  monitor = \"val_loss\", # monitor validation loss as evaluation \n",
    "  mode = \"min\",\n",
    "  filename = \"{name}-{epoch:02d}-{val_loss:.2f}\",\n",
    ")\n",
    "\n",
    "# Define a tensorboard logger\n",
    "i_tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"lightning_logs/\", name=i_name)\n",
    "\n",
    "\n",
    "interpretable_trainer =  pl.Trainer(\n",
    "  accelerator='auto' # use GPU if available\n",
    "  ,max_epochs=500\n",
    "  ,callbacks=[i_chk_callback]  \n",
    "  ,logger=[i_tb_logger]\n",
    ")\n",
    "\n",
    "interpretable_trainer.fit(interpretable_milkmodel, datamodule=dm)\n",
    "interpretable_trainer.validate(interpretable_milkmodel, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the trained models to make predictions. We will use the trained models to predict the next quarters worth of milk production.  However, we reuse the validation data in this test example to see how well the models predict the validation data.  In a real world scenario, we would use the trained models to predict the next quarters worth of milk production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "historical_data = torch.tensor(milkval[-backcast_length - forecast_length:- forecast_length], dtype=torch.float32).view(1, -1)\n",
    "\n",
    "# Create forecasting dataloader\n",
    "predict_dataset = ForecastingDataset(historical_data)\n",
    "predict_dataloader = DataLoader(predict_dataset, batch_size=1)\n",
    "\n",
    "# The model uses a ptl trainer to predict\n",
    "g1_predictions = generic_trainer.predict(g1, dataloaders=predict_dataloader)\n",
    "g2_predictions = generic_trainer.predict(g2, dataloaders=predict_dataloader)\n",
    "interpretable_predictions = interpretable_trainer.predict(interpretable_milkmodel, dataloaders=predict_dataloader)\n",
    "\n",
    "# The trainer returns a list of dictionaries, one for each dataloader passed to trainer.predict.  We only want the first and only one.\n",
    "g1_predictions = g1_predictions[0].squeeze()\n",
    "g2_predictions = g2_predictions[0].squeeze()\n",
    "interpretable_predictions = interpretable_predictions[0].squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the date range of the precicitons to be the last quarter of the validation data. Also we will only plot a subset of the the data for ease of viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "predicted_months = pd.date_range(start=\"1975-06\", periods=forecast_length, freq='M').strftime('%Y-%m')\n",
    "g1_df = pd.DataFrame(g1_predictions, index=predicted_months)\n",
    "g2_df = pd.DataFrame(g2_predictions, index=predicted_months)\n",
    "\n",
    "\n",
    "# Plot a subset of the data\n",
    "interpretable_df = pd.DataFrame(interpretable_predictions, index=predicted_months)\n",
    "milk_subset = milk[milk.index > '1971-01']\n",
    "milk_subset.index=milk_subset.index.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Matplotlib to plot the predictions of the models against the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(milk_subset.index, milk_subset['milk_production_pounds'], marker='o', linestyle='-', color='b')\n",
    "plt.plot(g1_df.index, g1_df, marker='o', linestyle='-', color='g')\n",
    "plt.plot(g2_df.index, g2_df, marker='o', linestyle='-', color='lightgreen')\n",
    "plt.plot(interpretable_df.index, interpretable_df, marker='o', linestyle='-', color='indigo')\n",
    "plt.title('Milk Production Over Time (1971-1975)', fontsize=14)\n",
    "plt.xlabel('Time (Year-Month)', fontsize=12)\n",
    "plt.ylabel('Milk Production (lbs)', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbeats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
